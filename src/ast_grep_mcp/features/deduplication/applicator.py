"""Apply deduplication refactoring with validation and rollback."""

import os
from typing import Any, Dict, List, Optional

from ...core.logging import get_logger
from .applicator_backup import DeduplicationBackupManager
from .applicator_executor import RefactoringExecutor
from .applicator_post_validator import RefactoringPostValidator
from .applicator_validator import RefactoringPlanValidator
from .generator import CodeGenerator

__all__ = [
    'DeduplicationApplicator',
    '_plan_file_modification_order',
    '_add_import_to_content',
    '_generate_import_for_extracted_function'
]


class DeduplicationApplicator:
    """Applies deduplication refactoring with backup and validation."""

    def __init__(self) -> None:
        """Initialize the deduplication applicator."""
        self.logger = get_logger("deduplication.applicator")
        self.code_generator = CodeGenerator()
        self.validator = RefactoringPlanValidator()
        self.executor = RefactoringExecutor()
        self.post_validator = RefactoringPostValidator()

    def apply_deduplication(
        self,
        project_folder: str,
        group_id: int,
        refactoring_plan: Dict[str, Any],
        dry_run: bool = True,
        backup: bool = True,
        extract_to_file: Optional[str] = None
    ) -> Dict[str, Any]:
        """Apply automated deduplication refactoring with comprehensive syntax validation.

        Phase 3.5 VALIDATION PIPELINE:
        1. PRE-VALIDATION: Validate all generated code before applying
        2. APPLICATION: Create backup and apply changes
        3. POST-VALIDATION: Validate modified files
        4. AUTO-ROLLBACK: Restore from backup if validation fails

        Args:
            project_folder: The absolute path to the project folder
            group_id: The duplication group ID from find_duplication results
            refactoring_plan: The refactoring plan with generated_code, files_affected, strategy, language
            dry_run: Preview changes without applying (default: true for safety)
            backup: Create backup before applying changes (default: true)
            extract_to_file: Where to place extracted function (auto-detect if None)

        Returns:
            Dict with:
            - status: "preview" | "success" | "failed" | "rolled_back"
            - validation: Pre and post validation results with detailed errors
            - errors: Detailed error info with file, line, message, and suggested fix
        """
        self.logger.info(
            "apply_deduplication_start",
            project_folder=project_folder,
            group_id=group_id,
            dry_run=dry_run,
            backup=backup
        )

        # Initialize validation results
        validation_result: Dict[str, Any] = {
            "pre_validation": {"passed": False, "errors": []},
            "post_validation": {"passed": False, "errors": []}
        }

        try:
            # Step 1: Validate and prepare plan
            plan_result = self._validate_and_prepare_plan(
                project_folder, refactoring_plan, validation_result,
                group_id, extract_to_file, dry_run, backup
            )
            if "early_return" in plan_result:
                return plan_result["early_return"]

            # Extract plan components
            files_to_modify = plan_result["files_to_modify"]
            generated_code = plan_result["generated_code"]
            language = plan_result["language"]
            strategy = plan_result["strategy"]
            orchestration_plan = plan_result["orchestration_plan"]
            backup_id = plan_result["backup_id"]

            # Step 2: Apply changes with validation
            apply_result = self._apply_changes_with_validation(
                orchestration_plan, generated_code, language, backup_id, project_folder
            )

            modified_files = apply_result["modified_files"]

            # Step 3: Handle post-validation and potential rollback
            rollback_response = self._validate_and_rollback_if_needed(
                modified_files, language, validation_result, backup_id,
                project_folder, group_id
            )
            if rollback_response:
                return rollback_response

            # Step 4: Build and return success response
            return self._build_success_response(
                modified_files, validation_result, backup_id,
                project_folder, group_id, strategy
            )

        except Exception as e:
            self.logger.error("apply_deduplication_failed", error=str(e)[:200])
            raise

    def _validate_and_prepare_plan(
        self,
        project_folder: str,
        refactoring_plan: Dict[str, Any],
        validation_result: Dict[str, Any],
        group_id: int,
        extract_to_file: Optional[str],
        dry_run: bool,
        backup: bool = True
    ) -> Dict[str, Any]:
        """Validate inputs, extract plan components, perform pre-validation and handle dry-run.

        This consolidated method combines validation, pre-validation, dry-run handling,
        and backup creation to reduce cyclomatic complexity in the main function.

        Args:
            project_folder: Project root folder
            refactoring_plan: The refactoring plan
            validation_result: Validation results dict
            group_id: Duplication group ID
            extract_to_file: Optional file to extract to
            dry_run: Whether in dry-run mode
            backup: Whether to create backup

        Returns:
            Dict with plan data or early_return response
        """
        # Extract and validate plan components
        plan_data = self._extract_plan_components(
            project_folder, refactoring_plan, validation_result, group_id, extract_to_file
        )
        if "early_return" in plan_data:
            return plan_data

        # Perform pre-validation
        pre_validation_response = self._perform_pre_validation(
            refactoring_plan, group_id, project_folder, validation_result, dry_run
        )
        if pre_validation_response:
            return {"early_return": pre_validation_response}

        # Handle dry-run mode
        if dry_run:
            return {
                "early_return": self._handle_dry_run(
                    plan_data["files_to_modify"],
                    validation_result,
                    group_id,
                    plan_data["strategy"]
                )
            }

        # Create backup if needed
        backup_id = self._create_backup_if_needed(
            backup,
            project_folder,
            plan_data["files_to_modify"],
            group_id,
            plan_data["strategy"]
        )

        # Return complete plan with backup_id
        return {
            **plan_data,
            "backup_id": backup_id
        }

    def _extract_plan_components(
        self,
        project_folder: str,
        refactoring_plan: Dict[str, Any],
        validation_result: Dict[str, Any],
        group_id: int,
        extract_to_file: Optional[str] = None
    ) -> Dict[str, Any]:
        """Validate inputs and extract plan components.

        Args:
            project_folder: Project root folder
            refactoring_plan: The refactoring plan
            validation_result: Validation results dict
            group_id: Duplication group ID
            extract_to_file: Optional file to extract to

        Returns:
            Dict with extracted plan data or early_return response
        """
        # Validate inputs
        if not os.path.isdir(project_folder):
            raise ValueError(f"Project folder does not exist: {project_folder}")
        if not refactoring_plan:
            raise ValueError("refactoring_plan is required")

        # Extract plan components
        files_affected = refactoring_plan.get("files_affected", [])
        generated_code = refactoring_plan.get("generated_code", {})
        language = refactoring_plan.get("language", "python")
        strategy = refactoring_plan.get("strategy", "extract_function")

        if not files_affected:
            return {
                "early_return": self._build_response(
                    "no_changes", "No files affected", validation_result,
                    dry_run=True, group_id=group_id
                )
            }

        # Resolve file paths
        files_to_modify = self._resolve_file_paths(files_affected, project_folder)
        if not files_to_modify:
            return {
                "early_return": self._build_response(
                    "no_files", "No valid files found", validation_result,
                    dry_run=True, group_id=group_id
                )
            }

        # Create orchestration plan
        orchestration_plan = self._plan_file_modification_order(
            files_to_modify, generated_code, extract_to_file, project_folder, language
        )

        return {
            "files_to_modify": files_to_modify,
            "generated_code": generated_code,
            "language": language,
            "strategy": strategy,
            "orchestration_plan": orchestration_plan
        }

    def _perform_pre_validation(
        self,
        refactoring_plan: Dict[str, Any],
        group_id: int,
        project_folder: str,
        validation_result: Dict[str, Any],
        dry_run: bool
    ) -> Optional[Dict[str, Any]]:
        """Perform pre-validation on the refactoring plan.

        Args:
            refactoring_plan: The refactoring plan
            group_id: Duplication group ID
            project_folder: Project root folder
            validation_result: Validation results dict
            dry_run: Whether in dry-run mode

        Returns:
            Error response if validation fails, None if successful
        """
        pre_validation_result = self.validator.validate_plan(
            refactoring_plan, group_id, project_folder
        )
        validation_result["pre_validation"] = pre_validation_result.to_dict()

        if not pre_validation_result.is_valid:
            return self._build_response(
                "failed",
                f"Pre-validation failed with {len(pre_validation_result.errors)} error(s)",
                validation_result,
                errors=pre_validation_result.errors,
                dry_run=dry_run,
                group_id=group_id
            )
        return None

    def _handle_dry_run(
        self,
        files_to_modify: List[str],
        validation_result: Dict[str, Any],
        group_id: int,
        strategy: str
    ) -> Dict[str, Any]:
        """Handle dry-run mode by building preview response.

        Args:
            files_to_modify: List of files that would be modified
            validation_result: Validation results
            group_id: Duplication group ID
            strategy: Refactoring strategy

        Returns:
            Dry-run preview response
        """
        return self._build_dry_run_response(
            files_to_modify, validation_result, group_id, strategy
        )

    def _create_backup_if_needed(
        self,
        backup: bool,
        project_folder: str,
        files_to_modify: List[str],
        group_id: int,
        strategy: str
    ) -> Optional[str]:
        """Create backup if requested.

        Args:
            backup: Whether to create backup
            project_folder: Project root folder
            files_to_modify: Files to backup
            group_id: Duplication group ID
            strategy: Refactoring strategy

        Returns:
            Backup ID if created, None otherwise
        """
        if not backup:
            return None

        backup_manager = DeduplicationBackupManager(project_folder)
        backup_id = backup_manager.create_backup(
            files=[fp for fp in files_to_modify if os.path.exists(fp)],
            metadata={
                "duplicate_group_id": group_id,
                "strategy": strategy,
                "file_count": len(files_to_modify)
            }
        )
        return backup_id

    def _apply_changes_with_validation(
        self,
        orchestration_plan: Dict[str, Any],
        generated_code: Dict[str, Any],
        language: str,
        backup_id: Optional[str],
        project_folder: str
    ) -> Dict[str, Any]:
        """Apply changes with error handling and potential rollback.

        Args:
            orchestration_plan: File modification plan
            generated_code: Generated code with replacements
            language: Programming language
            backup_id: Backup ID for rollback if needed
            project_folder: Project root folder

        Returns:
            Dict with modified_files
        """
        try:
            apply_result = self.executor.apply_changes(
                orchestration_plan,
                generated_code.get("replacements", {}),
                language,
                dry_run=False
            )
            return {
                "modified_files": apply_result["modified_files"]
            }

        except Exception as e:
            # Rollback on application failure
            if backup_id:
                backup_manager = DeduplicationBackupManager(project_folder)
                backup_manager.rollback(backup_id)
            raise

    def _validate_and_rollback_if_needed(
        self,
        modified_files: List[str],
        language: str,
        validation_result: Dict[str, Any],
        backup_id: Optional[str],
        project_folder: str,
        group_id: int
    ) -> Optional[Dict[str, Any]]:
        """Perform post-validation and rollback if needed.

        Args:
            modified_files: List of modified files
            language: Programming language
            validation_result: Validation results dict
            backup_id: Backup ID for rollback
            project_folder: Project root folder
            group_id: Duplication group ID

        Returns:
            Rollback response if validation fails, None if successful
        """
        post_validation_result = self.post_validator.validate_modified_files(
            modified_files, language
        )
        validation_result["post_validation"] = post_validation_result.to_dict()

        # AUTO-ROLLBACK if post-validation fails
        if not post_validation_result.is_valid and backup_id:
            backup_manager = DeduplicationBackupManager(project_folder)
            restored = backup_manager.rollback(backup_id)
            return self._build_response(
                "rolled_back",
                f"Rolled back due to {len(post_validation_result.errors)} validation error(s)",
                validation_result,
                files_restored=restored,
                backup_id=backup_id,
                errors=post_validation_result.errors,
                group_id=group_id
            )
        return None

    def _build_success_response(
        self,
        modified_files: List[str],
        validation_result: Dict[str, Any],
        backup_id: Optional[str],
        project_folder: str,
        group_id: int,
        strategy: str
    ) -> Dict[str, Any]:
        """Build success response.

        Args:
            modified_files: List of modified files
            validation_result: Validation results
            backup_id: Backup ID if created
            project_folder: Project root folder
            group_id: Duplication group ID
            strategy: Refactoring strategy

        Returns:
            Success response dictionary
        """
        response = self._build_response(
            "success",
            f"Applied deduplication to {len(modified_files)} file(s)",
            validation_result,
            files_modified=modified_files,
            backup_id=backup_id,
            group_id=group_id,
            strategy=strategy
        )

        if backup_id:
            response["rollback_command"] = (
                f"rollback_rewrite(project_folder='{project_folder}', "
                f"backup_id='{backup_id}')"
            )

        return response

    def _resolve_file_paths(
        self,
        files_affected: List[Any],
        project_folder: str
    ) -> List[str]:
        """Resolve file paths from files_affected list.

        Args:
            files_affected: List of file paths or file info dicts
            project_folder: Project root folder

        Returns:
            List of resolved absolute file paths
        """
        files_to_modify = []
        for file_info in files_affected:
            file_path = file_info if isinstance(file_info, str) else file_info.get("file", "")
            if file_path and os.path.isfile(file_path):
                files_to_modify.append(file_path)
            elif file_path and os.path.isfile(os.path.join(project_folder, file_path)):
                files_to_modify.append(os.path.join(project_folder, file_path))
        return files_to_modify

    def _build_response(
        self,
        status: str,
        message: str,
        validation_result: Dict[str, Any],
        **kwargs: Any
    ) -> Dict[str, Any]:
        """Build standardized response dictionary.

        Args:
            status: Response status
            message: Response message
            validation_result: Validation results
            **kwargs: Additional response fields

        Returns:
            Response dictionary
        """
        response = {
            "status": status,
            "message": message,
            "validation": validation_result,
            "dry_run": kwargs.get("dry_run", False)
        }
        response.update(kwargs)
        return response

    def _build_dry_run_response(
        self,
        files_to_modify: List[str],
        validation_result: Dict[str, Any],
        group_id: int,
        strategy: str
    ) -> Dict[str, Any]:
        """Build dry run preview response.

        Args:
            files_to_modify: List of files that would be modified
            validation_result: Validation results
            group_id: Duplication group ID
            strategy: Refactoring strategy

        Returns:
            Preview response dictionary
        """
        changes_preview = []
        for fp in files_to_modify:
            with open(fp, 'r') as f:
                changes_preview.append({
                    "file": fp,
                    "lines": len(f.read().splitlines())
                })

        return {
            "status": "preview",
            "dry_run": True,
            "message": f"Preview of changes to {len(files_to_modify)} file(s)",
            "changes_preview": changes_preview,
            "validation": validation_result,
            "group_id": group_id,
            "strategy": strategy
        }

    def _plan_file_modification_order(
        self,
        files_to_modify: List[str],
        generated_code: Dict[str, Any],
        extract_to_file: Optional[str],
        project_folder: str,
        language: str
    ) -> Dict[str, Any]:
        """Plan the order of file modifications for atomic deduplication."""
        plan: Dict[str, Any] = {
            "create_files": [],
            "update_files": [],
            "import_additions": {}
        }

        extracted_function = generated_code.get("extracted_function", "")
        function_name = generated_code.get("function_name", "extracted_function")

        # Determine target file for extracted function
        target_file = extract_to_file or generated_code.get("extract_to_file")
        if not target_file and files_to_modify:
            # Auto-detect: create utilities module
            first_file = files_to_modify[0]
            file_dir = os.path.dirname(first_file)
            ext = os.path.splitext(first_file)[1]
            target_file = os.path.join(file_dir, f"_extracted_utils{ext}")

        if target_file and not os.path.isabs(target_file):
            target_file = os.path.join(project_folder, target_file)

        # Plan file creation for extracted function
        if extracted_function and target_file:
            append_mode = os.path.exists(target_file)
            plan["create_files"].append({
                "path": target_file,
                "content": extracted_function,
                "append": append_mode,
                "operation": "append" if append_mode else "create"
            })

        # Plan updates for duplicate location files
        for file_path in files_to_modify:
            plan["update_files"].append({
                "path": file_path,
                "operation": "replace_duplicate"
            })

            # Generate import statement if needed
            if extracted_function and target_file and file_path != target_file:
                import_stmt = self._generate_import_for_extracted_function(
                    source_file=file_path,
                    target_file=target_file,
                    function_name=function_name,
                    project_folder=project_folder,
                    language=language
                )

                if import_stmt:
                    plan["import_additions"][file_path] = {
                        "import_statement": import_stmt,
                        "from_file": target_file,
                        "function_name": function_name
                    }

        return plan

    def _generate_import_for_extracted_function(
        self,
        source_file: str,
        target_file: str,
        function_name: str,
        project_folder: str,
        language: str
    ) -> str:
        """Generate import statement for an extracted function."""
        # Calculate relative path from source to target
        source_dir = os.path.dirname(source_file)
        target_rel = os.path.relpath(target_file, source_dir)

        # Convert path to module path
        module_path = os.path.splitext(target_rel)[0]
        module_path = module_path.replace(os.sep, ".")
        module_path = module_path.replace("/", ".")

        # Handle parent directory references
        if module_path.startswith(".."):
            # Convert ../foo to relative import
            parts = module_path.split(".")
            parent_count = sum(1 for p in parts if p == "")
            module_parts = [p for p in parts if p and p != ".."]
            module_path = "." * parent_count + ".".join(module_parts)

        # Generate import using code generator
        return self.code_generator.generate_import_statement(
            module_path=module_path,
            import_names=[function_name],
            is_relative=module_path.startswith(".")
        )

    def _add_import_to_content(
        self,
        content: str,
        import_statement: str,
        language: str
    ) -> str:
        """Add an import statement to file content."""
        if not import_statement:
            return content

        lines = content.split('\n')
        lang = language.lower()

        # Check if import already exists
        if import_statement.strip() in content:
            return content

        if lang == "python":
            # Find last import statement
            last_import_idx = -1
            for i, line in enumerate(lines):
                stripped = line.strip()
                if stripped.startswith("import ") or stripped.startswith("from "):
                    last_import_idx = i
                elif stripped and not stripped.startswith("#") and last_import_idx >= 0:
                    break

            if last_import_idx >= 0:
                lines.insert(last_import_idx + 1, import_statement)
            else:
                # No imports found, add at the top after any shebang/encoding
                insert_idx = 0
                for i, line in enumerate(lines):
                    if not line.strip() or line.startswith("#"):
                        insert_idx = i + 1
                    else:
                        break
                lines.insert(insert_idx, import_statement)
                if insert_idx > 0:
                    lines.insert(insert_idx, "")

        elif lang in ("javascript", "typescript", "jsx", "tsx"):
            # Add after last import/require
            last_import_idx = -1
            for i, line in enumerate(lines):
                if "import " in line or "require(" in line:
                    last_import_idx = i

            if last_import_idx >= 0:
                lines.insert(last_import_idx + 1, import_statement)
            else:
                lines.insert(0, import_statement)
                lines.insert(1, "")

        elif lang == "java":
            # Add after package statement but before class
            package_idx = -1
            last_import_idx = -1
            for i, line in enumerate(lines):
                if line.strip().startswith("package "):
                    package_idx = i
                elif line.strip().startswith("import "):
                    last_import_idx = i

            if last_import_idx >= 0:
                lines.insert(last_import_idx + 1, import_statement)
            elif package_idx >= 0:
                lines.insert(package_idx + 1, "")
                lines.insert(package_idx + 2, import_statement)
            else:
                lines.insert(0, import_statement)
                lines.insert(1, "")

        else:
            # Default: add at the top
            lines.insert(0, import_statement)
            lines.insert(1, "")

        return '\n'.join(lines)

    def _validate_code_for_language(self, code: str, language: str) -> tuple[bool, str]:
        """Basic syntax validation for generated code."""
        # This is a simplified version - in production, use proper parsers
        lang = language.lower()

        if lang == "python":
            try:
                compile(code, '<string>', 'exec')
                return True, ""
            except SyntaxError as e:
                return False, str(e)

        # For other languages, do basic checks
        return True, ""

    def _suggest_syntax_fix(self, error: Optional[str], language: str) -> str:
        """Suggest a fix for common syntax errors."""
        if not error:
            return "Check syntax and indentation"

        lang = language.lower()
        error_lower = error.lower()

        if lang == "python":
            if "indentation" in error_lower:
                return "Check indentation - Python uses 4 spaces"
            elif "invalid syntax" in error_lower:
                return "Check for missing colons, parentheses, or quotes"

        return "Review the generated code for syntax errors"


# Module-level functions for backward compatibility with tests
_applicator_instance = None

def _get_applicator() -> Any:
    """Get or create the global applicator instance."""
    global _applicator_instance
    if _applicator_instance is None:
        _applicator_instance = DeduplicationApplicator()
    return _applicator_instance

def _plan_file_modification_order(
    files_to_modify: List[str],
    generated_code: Dict[str, Any],
    extract_to_file: Optional[str],
    project_folder: str,
    language: str
) -> Dict[str, Any]:
    """Module-level wrapper for _plan_file_modification_order."""
    result = _get_applicator()._plan_file_modification_order(
        files_to_modify, generated_code, extract_to_file, project_folder, language
    )
    assert isinstance(result, dict)
    return result

def _add_import_to_content(
    content: str,
    import_statement: str,
    language: str
) -> str:
    """Module-level wrapper for _add_import_to_content."""
    result = _get_applicator()._add_import_to_content(content, import_statement, language)
    assert isinstance(result, str)
    return result

def _generate_import_for_extracted_function(
    source_file: str,
    target_file: str,
    function_name: str,
    language: str,
    project_folder: str
) -> str:
    """Module-level wrapper for _generate_import_for_extracted_function."""
    result = _get_applicator()._generate_import_for_extracted_function(
        source_file, target_file, function_name, language, project_folder
    )
    assert isinstance(result, str)
    return result
